{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aerial-malpractice",
   "metadata": {},
   "source": [
    "# Exploratory Analysis - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-marathon",
   "metadata": {},
   "source": [
    "Dataprep.EDA\n",
    "* Main Site - https://dataprep.ai/\n",
    "* Docs - https://docs.dataprep.ai/user_guide/eda/introduction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-confusion",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[EDA DF](#eda_df)\n",
    "* [Basic Data Overview](#basic_data_overview)  \n",
    "* [General Exploration - Dataprep.EDA](#dataprep)  \n",
    "* [Specific Questions:](#specific_questions)\n",
    "    * [Average Point Spread Error Per Game Over Time](#apsepgot)  \n",
    "\n",
    "[Game Records](#game_records)\n",
    "* [Data Overview](#data_overview)  \n",
    "* [Specific Questions:](#specific_questions_2)\n",
    "    * [Model Performance Over Time](#mpot)\n",
    "    * [Distributions of Model Predictions, Vegas Predictions, and Game Results](#dmpvpgp)\n",
    "    * [Overall Winning vs. Losing Predictions](#owvlp)\n",
    "    * [Win Percentage vs. Prediction Margin](#wpvpm)\n",
    "* [Game Score and Component Score Accuracy](#gscsa)\n",
    "    * [Overall](#overall)\n",
    "    * [Game Score](#gamescore)\n",
    "    * [ML Predictions](#ml)\n",
    "    * [DL Predictions](#dl)\n",
    "    * [Covers Consensus](#covers)\n",
    "    * [FiveThirtyEight Raptor](#raptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-geneva",
   "metadata": {},
   "source": [
    "## Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chinese-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from dataprep.eda import plot, plot_correlation, plot_missing, create_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../')\n",
    "from passkeys import RDS_ENDPOINT, RDS_PASSWORD\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.options.display.max_info_columns = 1000\n",
    "pd.options.display.precision = 5\n",
    "\n",
    "# Graphing Settings\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-routine",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annual-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'postgres'\n",
    "password = RDS_PASSWORD\n",
    "endpoint = RDS_ENDPOINT\n",
    "database = 'nba_betting'\n",
    "port = '5432'\n",
    "\n",
    "connection = create_engine(f'postgresql+psycopg2://{username}:{password}@{endpoint}/{database}').connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-neighborhood",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fossil-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records = pd.read_sql_table('game_records', connection)\n",
    "combined_inbound_data = pd.read_sql_table('combined_inbound_data', connection)\n",
    "model_training_data = pd.read_sql_table('model_training_data', connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-polish",
   "metadata": {},
   "source": [
    "<a id='eda_df'></a>\n",
    "\n",
    "# EDA_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1cc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8271efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-idaho",
   "metadata": {},
   "source": [
    "<a id='basic_data_overview'></a>\n",
    "\n",
    "## Basic Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c8021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_data.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "choice-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "negative-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cb819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_features = [\n",
    "        \"home_team_num\",\n",
    "        \"away_team_num\",\n",
    "        \"home_spread\",\n",
    "        \"league_year_end\",\n",
    "        \"day_of_season\",\n",
    "        \"elo1_pre\",\n",
    "        \"elo2_pre\",\n",
    "        \"elo_prob1\",\n",
    "        \"elo_prob2\",\n",
    "    ]\n",
    "targets = ['CLS_TARGET_home_margin_GT_home_spread', 'REG_TARGET_actual_home_margin']\n",
    "main_features_df = model_training_data[targets + main_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "558f7971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2dfa3",
   "metadata": {},
   "source": [
    "<a id='dataprep'></a>\n",
    "\n",
    "# DataPrep Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "excited-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep_report = create_report(main_features_df)\n",
    "dataprep_report.show_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-stick",
   "metadata": {},
   "source": [
    "<a id=specific_questions></a>\n",
    "\n",
    "## Specific Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-arnold",
   "metadata": {},
   "source": [
    "<a id=apsepgot></a>\n",
    "\n",
    "### Average Point Spread Error Per Game Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab2a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = game_records.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b551bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df['year'] = eda_df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bddda2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df['vegas_predicted_home_margin_of_victory'] = -eda_df['home_line']\n",
    "# If negative, Home team is predicted to lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400583c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df['ml_predicted_home_margin_of_victory'] = eda_df['ml_reg_prediction']\n",
    "eda_df['dl_predicted_home_margin_of_victory'] = eda_df['dl_reg_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9b24413",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df['actual_home_margin_of_victory'] = eda_df['game_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "800616b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate differences\n",
    "eda_df['vegas_diff'] = eda_df['vegas_predicted_home_margin_of_victory'] - eda_df['actual_home_margin_of_victory']\n",
    "eda_df['ml_diff'] = eda_df['ml_predicted_home_margin_of_victory'] - eda_df['actual_home_margin_of_victory']\n",
    "eda_df['dl_diff'] = eda_df['dl_predicted_home_margin_of_victory'] - eda_df['actual_home_margin_of_victory']\n",
    "\n",
    "# create new columns for high/low/exact\n",
    "eda_df['vegas_result'] = pd.cut(eda_df['vegas_diff'], [-float('inf'), 0, float('inf')], labels=['Low', 'High'], include_lowest=True)\n",
    "eda_df['ml_result'] = pd.cut(eda_df['ml_diff'], [-float('inf'), 0, float('inf')], labels=['Low', 'High'], include_lowest=True)\n",
    "eda_df['dl_result'] = pd.cut(eda_df['dl_diff'], [-float('inf'), 0, float('inf')], labels=['Low', 'High'], include_lowest=True)\n",
    "eda_df[['vegas_result', 'ml_result', 'dl_result']] = eda_df[['vegas_result', 'ml_result', 'dl_result']]\n",
    "\n",
    "# absolute differences\n",
    "eda_df['vegas_abs_diff'] = eda_df['vegas_diff'].abs()\n",
    "eda_df['ml_abs_diff'] = eda_df['ml_diff'].abs()\n",
    "eda_df['dl_abs_diff'] = eda_df['dl_diff'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "678a618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "random-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_mean_abs_diff = round(eda_df['vegas_diff'].abs().mean(), 2)\n",
    "ml_mean_abs_diff = round(eda_df['ml_diff'].abs().mean(), 2)\n",
    "dl_mean_abs_diff = round(eda_df['dl_diff'].abs().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b2d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Differences:\")\n",
    "print(f\"Vegas: {vegas_mean_abs_diff}\")\n",
    "print(f\"ML: {ml_mean_abs_diff}\")\n",
    "print(f\"DL: {dl_mean_abs_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5c9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8524e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = eda_df.groupby('year').agg({'vegas_abs_diff': 'mean', 'ml_abs_diff': 'mean', 'dl_abs_diff': 'mean'})\n",
    "grouped_df = grouped_df.abs().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f13de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Differences Grouped by Year:\")\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unexpected-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create line plot of grouped mean absolute differences\n",
    "\n",
    "def spread_miss_graph(vegas_only=True, save=False, image_name=None):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.set_title('Average Point Spread Error Per Game', fontsize=24, pad=16, fontweight='bold')\n",
    "    ax.set_xlabel('Year', fontsize=18, labelpad=8, fontweight='bold')\n",
    "    ax.set_ylabel('Spread Error (Points)', fontsize=18, labelpad=8, fontweight='bold')\n",
    "    ax.set_ylim(top=11, bottom=8)\n",
    "\n",
    "    sns.lineplot(x=grouped_df.index, y='vegas_abs_diff', data=grouped_df, ax=ax,\n",
    "                 linewidth=4, color='#17408B', label='Vegas')\n",
    "\n",
    "    # Vegas Only\n",
    "    if vegas_only:\n",
    "        ax.axhline(vegas_mean_abs_diff, color='#C9082A', linestyle='--', linewidth=2)\n",
    "        ax.text(x=2014.01, y=vegas_mean_abs_diff + 0.05, s=f'Overall Average: {vegas_mean_abs_diff} PPG', color='#C9082A', fontsize=16, fontweight='bold')\n",
    "\n",
    "    if not vegas_only:\n",
    "        sns.lineplot(x=grouped_df.index, y='ml_abs_diff', data=grouped_df, ax=ax,\n",
    "                     linewidth=4, color='#C9082A', label='ML')\n",
    "        sns.lineplot(x=grouped_df.index, y='dl_abs_diff', data=grouped_df, ax=ax,\n",
    "                     linewidth=4, color='#00A6D6', label='DL')\n",
    "\n",
    "        ax.axhline(vegas_mean_abs_diff, color='#17408B', linestyle='--', linewidth=2,\n",
    "                   label=f'Vegas (Overall Avg: {vegas_mean_abs_diff})')\n",
    "        ax.axhline(ml_mean_abs_diff, color='#C9082A', linestyle='--', linewidth=2,\n",
    "                   label=f'Machine Learning (Overall Avg: {ml_mean_abs_diff})')\n",
    "        ax.axhline(dl_mean_abs_diff, color='#00A6D6', linestyle='--', linewidth=2,\n",
    "                   label=f'Deep Learning (Overall Avg: {dl_mean_abs_diff})')\n",
    "\n",
    "    plt.xticks(grouped_df.index, fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.legend(fontsize=16)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'../images/{image_name}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12c60b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_miss_graph(vegas_only=True, save=False, image_name=\"spread_miss_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-emission",
   "metadata": {},
   "source": [
    "<a id=game_records></a>\n",
    "\n",
    "# Game Records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-dutch",
   "metadata": {},
   "source": [
    "## Setting Up Features, Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "utility-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['vegas_hv_pred'] = game_records['home_line'].apply(lambda x: -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "committed-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['ml_hv_pred'] = game_records['ml_reg_prediction']\n",
    "game_records['dl_hv_pred'] = game_records['dl_reg_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "developing-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['vegas_miss'] = game_records.apply(lambda x: abs(x['game_result'] - x['vegas_hv_pred']),\n",
    "                                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "romantic-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['model_miss_ml'] = game_records.apply(lambda x: abs(x['game_result'] - x['ml_hv_pred']),\n",
    "                                                   axis=1)\n",
    "game_records['model_miss_dl'] = game_records.apply(lambda x: abs(x['game_result'] - x['dl_hv_pred']),\n",
    "                                                   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "professional-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['ml_model_v_vegas'] = game_records.apply(lambda x: 'vegas' if x['vegas_miss'] < x['model_miss_ml'] else 'ml_model', axis=1)\n",
    "game_records['dl_model_v_vegas'] = game_records.apply(lambda x: 'vegas' if x['vegas_miss'] < x['model_miss_dl'] else 'dl_model', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "transsexual-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['ml_pred_line_margin'] = game_records['ml_hv_pred'] - game_records['vegas_hv_pred']\n",
    "game_records['dl_pred_line_margin'] = game_records['dl_hv_pred'] - game_records['vegas_hv_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "residential-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['game_result_direction'] = game_records.apply(lambda x: 'Home' if x['game_result'] >= x['vegas_hv_pred'] else 'Away', axis=1)\n",
    "game_records['covers_pred_direction'] = game_records['covers_home_score'].apply(lambda x: x if pd.isnull(x) else ('Home' if x >= 50 else 'Away'))\n",
    "game_records['raptor_pred_direction'] = game_records['raptor_home_score'].apply(lambda x: x if pd.isnull(x) else ('Home' if x >= 50 else 'Away'))\n",
    "game_records['ml_pred_direction'] = game_records['ml_home_score'].apply(lambda x: 'Home' if x >= 50 else 'Away')\n",
    "game_records['dl_pred_direction'] = game_records['dl_home_score'].apply(lambda x: 'Home' if x >= 50 else 'Away')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-diamond",
   "metadata": {},
   "source": [
    "<a id=data_overview></a>\n",
    "\n",
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "biblical-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "destroyed-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "actual-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exotic-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(game_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-baseball",
   "metadata": {},
   "source": [
    "<a id=specific_questions_2></a>\n",
    "\n",
    "## Specific Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-processing",
   "metadata": {},
   "source": [
    "#### Future Questions\n",
    "* Does Winning Percentage increase as Game Score increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-coupon",
   "metadata": {},
   "source": [
    "<a id=mpot></a>\n",
    "\n",
    "### Model Performance Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-tuesday",
   "metadata": {},
   "source": [
    "#### Overall Prediction Miss Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interracial-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_miss_avg = round(game_records['vegas_miss'].mean(), 2)\n",
    "ml_model_miss_avg = round(game_records['model_miss_ml'].mean(), 2)\n",
    "dl_model_miss_avg = round(game_records['model_miss_dl'].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "medieval-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Vegas Miss Average: {vegas_miss_avg}')\n",
    "print(f'ML Model Miss Average: {ml_model_miss_avg}')\n",
    "print(f'DL Model Miss Average: {dl_model_miss_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-tumor",
   "metadata": {},
   "source": [
    "#### Prediction Miss Average by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "possible-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = game_records.groupby(game_records.date.dt.year).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "invalid-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df[['vegas_miss', 'model_miss_ml', 'model_miss_dl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "copyrighted-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(data=date_df, x='date', y='vegas_miss', ax=ax, color='r', linewidth=4)\n",
    "sns.lineplot(data=date_df, x='date', y='model_miss_ml', ax=ax, color='g', linewidth=4)\n",
    "sns.lineplot(data=date_df, x='date', y='model_miss_dl', ax=ax, color='orange', linewidth=4)\n",
    "\n",
    "ax.set_title('Average Prediction Miss Amount Over Time', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Year', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Prediction Miss (Points)', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Vegas')\n",
    "green_patch = mpatches.Patch(color='g', label='ML Model')\n",
    "orange_patch = mpatches.Patch(color='orange', label='DL Model')\n",
    "ax.legend(handles=[red_patch, green_patch, orange_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "incorrect-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df_2 = game_records.groupby([game_records.date.dt.year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "comfortable-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_win_pct_by_year = date_df_2['ml_model_v_vegas'].value_counts(normalize=True)[:, 'ml_model']\n",
    "dl_win_pct_by_year = date_df_2['dl_model_v_vegas'].value_counts(normalize=True)[:, 'dl_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "sound-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_win_pct_by_year = pd.concat([ml_win_pct_by_year, dl_win_pct_by_year], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "immune-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_win_pct_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "opponent-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(data=model_win_pct_by_year, x='date', y='ml_model_v_vegas', ax=ax, color='g', linewidth=4)\n",
    "sns.lineplot(data=model_win_pct_by_year, x='date', y='dl_model_v_vegas',\n",
    "             ax=ax, color='orange', linewidth=4)\n",
    "\n",
    "ax.set_title('Average Win Probability Over Time', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Year', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Win Probability', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "green_patch = mpatches.Patch(color='g', label='ML Model')\n",
    "orange_patch = mpatches.Patch(color='orange', label='DL Model')\n",
    "ax.legend(handles=[green_patch, orange_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-disease",
   "metadata": {},
   "source": [
    "<a id=dmpvpgp></a>\n",
    "\n",
    "### Distributions of Model Predictions, Vegas Predictions, and Game Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "psychological-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.kdeplot(data=game_records, x=\"game_result\", ax=ax, color='b', fill=True)\n",
    "sns.kdeplot(data=game_records, x=\"vegas_hv_pred\", ax=ax, color='r', fill=False)\n",
    "sns.kdeplot(data=game_records, x=\"ml_hv_pred\", ax=ax, color='g', fill=False)\n",
    "sns.kdeplot(data=game_records, x=\"dl_hv_pred\", ax=ax, color='orange', fill=False)\n",
    "\n",
    "ax.set_title('Distribution of Home Team Win Margin', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Home Win Margin', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Density', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "blue_patch = mpatches.Patch(color='b', label='Actual Result')\n",
    "red_patch = mpatches.Patch(color='r', label='Vegas')\n",
    "green_patch = mpatches.Patch(color='g', label='ML Model')\n",
    "orange_patch = mpatches.Patch(color='orange', label='DL Model')\n",
    "ax.legend(handles=[blue_patch, red_patch, green_patch, orange_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-savannah",
   "metadata": {},
   "source": [
    "<a id='owvlp'></a>\n",
    "\n",
    "### Overall Winning vs. Losing Predictions\n",
    "Must win 52.4% to overcome -110 vig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "soviet-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['ml_model_v_vegas'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "competitive-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['ml_model_v_vegas'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "electronic-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['dl_model_v_vegas'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "natural-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['dl_model_v_vegas'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-medline",
   "metadata": {},
   "source": [
    "<a id='wpvpm'></a>\n",
    "\n",
    "### Win Percentage vs. Prediction Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "detected-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.histplot(data=game_records, x='ml_pred_line_margin',\n",
    "             hue='ml_model_v_vegas', kde=True, ax=ax, bins=[0,2,4,6,8,10,15,20],\n",
    "             palette=('#17408B', '#C9082A'), multiple='dodge')\n",
    "\n",
    "ax.set_title('Distribution of Bet Wins by Prediction Margin', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Prediction Margin', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Count', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "blue_patch = mpatches.Patch(color='b', label='ML Model')\n",
    "red_patch = mpatches.Patch(color='r', label='Vegas')\n",
    "ax.legend(handles=[blue_patch, red_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dangerous-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.histplot(data=game_records, x='dl_pred_line_margin',\n",
    "             hue='dl_model_v_vegas', kde=True, ax=ax, bins=[0,2,4,6,8,10,15,20],\n",
    "             palette=('#17408B', '#C9082A'), multiple='dodge')\n",
    "\n",
    "ax.set_title('Distribution of Bet Wins by Prediction Margin', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Prediction Margin', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Count', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "blue_patch = mpatches.Patch(color='b', label='DL Model')\n",
    "red_patch = mpatches.Patch(color='r', label='Vegas')\n",
    "ax.legend(handles=[blue_patch, red_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-hometown",
   "metadata": {},
   "source": [
    "<a id=gscsa></a>\n",
    "\n",
    "## Game Score and Component Score Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "racial-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_records['game_score_is_correct'] = game_records.apply(lambda x: x['game_score_direction'] \n",
    "                                                           if pd.isnull(x['game_score_direction']) \n",
    "                                                           else (x['game_score_direction'] == \n",
    "                                                                 x['game_result_direction']), axis=1)\n",
    "game_records['ml_pred_is_correct'] = game_records.apply(lambda x: x['ml_pred_direction'] \n",
    "                                                           if pd.isnull(x['ml_pred_direction']) \n",
    "                                                           else (x['ml_pred_direction'] == \n",
    "                                                                 x['game_result_direction']), axis=1)\n",
    "game_records['dl_pred_is_correct'] = game_records.apply(lambda x: x['dl_pred_direction'] \n",
    "                                                           if pd.isnull(x['dl_pred_direction']) \n",
    "                                                           else (x['dl_pred_direction'] == \n",
    "                                                                 x['game_result_direction']), axis=1)\n",
    "game_records['covers_is_correct'] = game_records.apply(lambda x: x['covers_pred_direction'] \n",
    "                                                           if pd.isnull(x['covers_pred_direction']) \n",
    "                                                           else int(x['covers_pred_direction'] == \n",
    "                                                                 x['game_result_direction']), axis=1)\n",
    "game_records['raptor_is_correct'] = game_records.apply(lambda x: x['raptor_pred_direction'] \n",
    "                                                           if pd.isnull(x['raptor_pred_direction']) \n",
    "                                                           else int(x['raptor_pred_direction'] == \n",
    "                                                                 x['game_result_direction']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "authentic-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Restrictions\n",
    "previous_years_only_df = game_records[game_records['date'] < datetime.strptime('20221001', \"%Y%m%d\")]\n",
    "this_year_only_df = game_records[game_records['date'] > datetime.strptime('20221001', \"%Y%m%d\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-honor",
   "metadata": {},
   "source": [
    "<a id=overall></a>\n",
    "\n",
    "### Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "buried-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_score_accuracy = game_records['game_score_is_correct'].mean()\n",
    "ml_pred_accuracy = game_records['ml_pred_is_correct'].mean()\n",
    "dl_pred_accuracy = game_records['dl_pred_is_correct'].mean()\n",
    "covers_accuracy = game_records['covers_is_correct'].mean()\n",
    "raptor_accuracy = game_records['raptor_is_correct'].mean()\n",
    "\n",
    "game_score_accuracy_py = previous_years_only_df['game_score_is_correct'].mean()\n",
    "ml_pred_accuracy_py = previous_years_only_df['ml_pred_is_correct'].mean()\n",
    "dl_pred_accuracy_py = previous_years_only_df['dl_pred_is_correct'].mean()\n",
    "covers_accuracy_py = previous_years_only_df['covers_is_correct'].mean()\n",
    "raptor_accuracy_py = previous_years_only_df['raptor_is_correct'].mean()\n",
    "\n",
    "game_score_accuracy_ty = this_year_only_df['game_score_is_correct'].mean()\n",
    "ml_pred_accuracy_ty = this_year_only_df['ml_pred_is_correct'].mean()\n",
    "dl_pred_accuracy_ty = this_year_only_df['dl_pred_is_correct'].mean()\n",
    "covers_accuracy_ty = this_year_only_df['covers_is_correct'].mean()\n",
    "raptor_accuracy_ty = this_year_only_df['raptor_is_correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "comparative-halifax",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Game Score Accuracy')\n",
    "print(f'Overall: {round(game_score_accuracy * 100, 2)}% - Previous Years: {round(game_score_accuracy_py * 100, 2)}% - This Year: {round(game_score_accuracy_ty * 100, 2)}%')\n",
    "print('ML Pred Accuracy')\n",
    "print(f'Overall: {round(ml_pred_accuracy * 100, 2)}% - Previous Years: {round(ml_pred_accuracy_py * 100, 2)}% - This Year: {round(ml_pred_accuracy_ty * 100, 2)}%')\n",
    "print('DL Pred Accuracy')\n",
    "print(f'Overall: {round(dl_pred_accuracy * 100, 2)}% - Previous Years: {round(dl_pred_accuracy_py * 100, 2)}% - This Year: {round(dl_pred_accuracy_ty * 100, 2)}%')\n",
    "print('Covers Accuracy')\n",
    "print(f'Overall: {round(covers_accuracy * 100, 2)}% - Previous Years: {round(covers_accuracy_py * 100, 2)}% - This Year: {round(covers_accuracy_ty * 100, 2)}%')\n",
    "print('Raptor Accuracy')\n",
    "print(f'Overall: {round(raptor_accuracy * 100, 2)}% - Previous Years: {round(raptor_accuracy_py * 100, 2)}% - This Year: {round(raptor_accuracy_ty * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "average-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = ['Random Guess', 'Profitable', 'Game Score', 'ML Model', 'DL Model', 'Covers', 'Raptor']\n",
    "y_data = [50.0,\n",
    "          52.4,\n",
    "          round(game_score_accuracy_ty * 100, 2),\n",
    "          round(ml_pred_accuracy_ty * 100, 2),\n",
    "          round(dl_pred_accuracy_ty * 100, 2),\n",
    "          round(covers_accuracy_ty * 100, 2),\n",
    "          round(raptor_accuracy_ty * 100, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "integral-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax = sns.barplot(x=x_data, y=y_data,\n",
    "             palette=('gray', 'gray', 'green', '#17408B', '#C9082A','yellow', 'purple'))\n",
    "\n",
    "ax.set_title('Prediction Accuracy', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy %', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "for p in ax.patches:\n",
    "             ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', fontsize=20, fontweight='bold', color='white', xytext=(0, -20),\n",
    "                 textcoords='offset points')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "image_name = 'prediction_accuracy'\n",
    "# plt.savefig(f'../images/{image_name}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-friend",
   "metadata": {},
   "source": [
    "<a id=gamescore></a>\n",
    "\n",
    "### Game Score Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "conceptual-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_game_score_accuracy = game_records.groupby(pd.cut(game_records['game_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['game_score_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "previous_years_game_score_accuracy = previous_years_only_df.groupby(pd.cut(previous_years_only_df['game_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['game_score_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "this_year_game_score_accuracy = this_year_only_df.groupby(pd.cut(this_year_only_df['game_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['game_score_is_correct'].agg(['mean', 'size']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "provincial-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_game_score_accuracy['bin_high'] = overall_game_score_accuracy['game_score'].apply(lambda x: x.right)\n",
    "previous_years_game_score_accuracy['bin_high'] = previous_years_game_score_accuracy['game_score'].apply(lambda x: x.right)\n",
    "this_year_game_score_accuracy['bin_high'] = this_year_game_score_accuracy['game_score'].apply(lambda x: x.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "configured-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_game_score_accuracy, '\\n\\n', previous_years_game_score_accuracy, '\\n\\n', this_year_game_score_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "assisted-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(data=overall_game_score_accuracy, x='bin_high', y='mean', ax=ax, color='r', linewidth=4)\n",
    "sns.lineplot(data=this_year_game_score_accuracy, x='bin_high', y='mean', ax=ax, color='b', linewidth=4)\n",
    "\n",
    "ax.set_title('Overall Win Percentage by Game Score', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Game Score', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Win Percentage', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Overall')\n",
    "blue_patch = mpatches.Patch(color='b', label='Current Year')\n",
    "ax.legend(handles=[red_patch, blue_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-immigration",
   "metadata": {},
   "source": [
    "<a id=ml></a>\n",
    "\n",
    "### ML Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "pleasant-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_ml_pred_accuracy = game_records.groupby(pd.cut(game_records['ml_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['ml_pred_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "previous_years_ml_pred_accuracy = previous_years_only_df.groupby(pd.cut(previous_years_only_df['ml_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['ml_pred_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "this_year_ml_pred_accuracy = this_year_only_df.groupby(pd.cut(this_year_only_df['ml_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['ml_pred_is_correct'].agg(['mean', 'size']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "korean-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_ml_pred_accuracy['bin_high'] = overall_ml_pred_accuracy['ml_home_score'].apply(lambda x: x.right)\n",
    "previous_years_ml_pred_accuracy['bin_high'] = previous_years_ml_pred_accuracy['ml_home_score'].apply(lambda x: x.right)\n",
    "this_year_ml_pred_accuracy['bin_high'] = this_year_ml_pred_accuracy['ml_home_score'].apply(lambda x: x.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "opposite-recycling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(overall_ml_pred_accuracy, '\\n\\n', previous_years_ml_pred_accuracy, '\\n\\n', this_year_ml_pred_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "identical-message",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(data=overall_ml_pred_accuracy, x='bin_high', y='mean', ax=ax, color='r', linewidth=4)\n",
    "sns.lineplot(data=this_year_ml_pred_accuracy, x='bin_high', y='mean', ax=ax, color='b', linewidth=4)\n",
    "\n",
    "ax.set_title('Overall Win Percentage by ML Home Score', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('ML Home Score', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Win Percentage', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Overall')\n",
    "blue_patch = mpatches.Patch(color='b', label='Current Year')\n",
    "ax.legend(handles=[red_patch, blue_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-fruit",
   "metadata": {},
   "source": [
    "<a id=dl></a>\n",
    "\n",
    "### DL Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "static-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dl_pred_accuracy = game_records.groupby(pd.cut(game_records['dl_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['dl_pred_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "previous_years_dl_pred_accuracy = previous_years_only_df.groupby(pd.cut(previous_years_only_df['dl_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['dl_pred_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "this_year_dl_pred_accuracy = this_year_only_df.groupby(pd.cut(this_year_only_df['dl_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['dl_pred_is_correct'].agg(['mean', 'size']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "liable-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dl_pred_accuracy['bin_high'] = overall_dl_pred_accuracy['dl_home_score'].apply(lambda x: x.right)\n",
    "previous_years_dl_pred_accuracy['bin_high'] = previous_years_dl_pred_accuracy['dl_home_score'].apply(lambda x: x.right)\n",
    "this_year_dl_pred_accuracy['bin_high'] = this_year_dl_pred_accuracy['dl_home_score'].apply(lambda x: x.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "insured-founder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(overall_dl_pred_accuracy, '\\n\\n', previous_years_dl_pred_accuracy, '\\n\\n', this_year_dl_pred_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "applicable-ebony",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(data=overall_dl_pred_accuracy, x='bin_high', y='mean', ax=ax, color='r', linewidth=4)\n",
    "sns.lineplot(data=this_year_dl_pred_accuracy, x='bin_high', y='mean', ax=ax, color='b', linewidth=4)\n",
    "\n",
    "ax.set_title('Overall Win Percentage by DL Home Score', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('DL Home Score', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Win Percentage', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Overall')\n",
    "blue_patch = mpatches.Patch(color='b', label='Current Year')\n",
    "ax.legend(handles=[red_patch, blue_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-interpretation",
   "metadata": {},
   "source": [
    "<a id=covers></a>\n",
    "\n",
    "### Covers Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "tender-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_covers_accuracy = game_records.groupby(pd.cut(game_records['covers_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['covers_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "previous_years_covers_accuracy = previous_years_only_df.groupby(pd.cut(previous_years_only_df['covers_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['covers_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "this_year_covers_accuracy = this_year_only_df.groupby(pd.cut(this_year_only_df['covers_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['covers_is_correct'].agg(['mean', 'size']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aging-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_covers_accuracy['bin_high'] = overall_covers_accuracy['covers_home_score'].apply(lambda x: x.right)\n",
    "previous_years_covers_accuracy['bin_high'] = previous_years_covers_accuracy['covers_home_score'].apply(lambda x: x.right)\n",
    "this_year_covers_accuracy['bin_high'] = this_year_covers_accuracy['covers_home_score'].apply(lambda x: x.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "inclusive-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_covers_accuracy, '\\n\\n', previous_years_covers_accuracy, '\\n\\n', this_year_covers_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "medium-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(data=overall_covers_accuracy, x='bin_high', y='mean', ax=ax, color='r', linewidth=4)\n",
    "sns.lineplot(data=this_year_covers_accuracy, x='bin_high', y='mean', ax=ax, color='b', linewidth=4)\n",
    "\n",
    "ax.set_title('Overall Win Percentage by Covers Home Score', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Covers Home Score', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Win Percentage', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Overall')\n",
    "blue_patch = mpatches.Patch(color='b', label='Current Year')\n",
    "ax.legend(handles=[red_patch, blue_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-lithuania",
   "metadata": {},
   "source": [
    "<a id=raptor></a>\n",
    "\n",
    "### Raptor Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "atomic-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_raptor_accuracy = game_records.groupby(pd.cut(game_records['raptor_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['raptor_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "previous_years_raptor_accuracy = previous_years_only_df.groupby(pd.cut(previous_years_only_df['raptor_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['raptor_is_correct'].agg(['mean', 'size']).reset_index()\n",
    "this_year_raptor_accuracy = this_year_only_df.groupby(pd.cut(this_year_only_df['raptor_home_score'],\n",
    "                                                          bins=list(range(0, 100, 5))))['raptor_is_correct'].agg(['mean', 'size']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "visible-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_raptor_accuracy['bin_high'] = overall_raptor_accuracy['raptor_home_score'].apply(lambda x: x.right)\n",
    "previous_years_raptor_accuracy['bin_high'] = previous_years_raptor_accuracy['raptor_home_score'].apply(lambda x: x.right)\n",
    "this_year_raptor_accuracy['bin_high'] = this_year_raptor_accuracy['raptor_home_score'].apply(lambda x: x.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eight-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_raptor_accuracy, '\\n\\n', previous_years_raptor_accuracy, '\\n\\n', this_year_raptor_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "laughing-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(data=overall_raptor_accuracy, x='bin_high', y='mean', ax=ax, color='r', linewidth=4)\n",
    "sns.lineplot(data=this_year_raptor_accuracy, x='bin_high', y='mean', ax=ax, color='b', linewidth=4)\n",
    "\n",
    "ax.set_title('Overall Win Percentage by Raptor Home Score', fontsize=24, pad=16, fontweight='bold')\n",
    "ax.set_xlabel('Raptor Home Score', fontsize=18, labelpad=8, fontweight='bold')\n",
    "ax.set_ylabel('Win Percentage', fontsize=18, labelpad=8, fontweight='bold')\n",
    "\n",
    "red_patch = mpatches.Patch(color='r', label='Overall')\n",
    "blue_patch = mpatches.Patch(color='b', label='Current Year')\n",
    "ax.legend(handles=[red_patch, blue_patch], fontsize='large')\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-ballot",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
