{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA AI - Currently in development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Data Setup](#data-setup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 18:40:51.184542: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-25 18:40:51.237263: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-25 18:40:51.238047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-25 18:40:52.411320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "from pycaret.regression import RegressionExperiment\n",
    "import autokeras as ak\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    ")\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.options.display.max_info_columns = 200\n",
    "pd.options.display.precision = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021_2022 = pd.read_csv(\"../data/nba_ai/cleaned_data_2021-2022.csv\")\n",
    "df_2022_2023 = pd.read_csv(\"../data/nba_ai/cleaned_data_2022-2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"data-setup\"></a>\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(train_df, cls_target, reg_target, test_df=None, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Prepares datasets for training and testing for both classification and regression targets,\n",
    "    ensuring time-sensitive splitting based on a 'date' column.\n",
    "\n",
    "    Parameters:\n",
    "    train_df (DataFrame): The training dataframe.\n",
    "    cls_target (str): The name of the classification target column.\n",
    "    reg_target (str): The name of the regression target column.\n",
    "    test_df (DataFrame, optional): An optional testing dataframe. If not provided, a portion of the training data is used.\n",
    "    test_size (float, optional): The proportion of the dataset to include in the test split (if test_df is not provided).\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing six dataframes:\n",
    "           (X_train, X_test, y_train_cls, y_test_cls, y_train_reg, y_test_reg).\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort the dataframe based on the 'date' column\n",
    "    train_df = train_df.sort_values(by=\"date\")\n",
    "\n",
    "    # If a test dataframe is not provided, split the training dataframe\n",
    "    if test_df is None:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            train_df.drop([cls_target, reg_target], axis=1),\n",
    "            train_df[[cls_target, reg_target]],\n",
    "            test_size=test_size,\n",
    "            shuffle=False,  # Important to maintain time order\n",
    "        )\n",
    "    else:\n",
    "        # If a test dataframe is provided, ensure it is also sorted by date\n",
    "        test_df = test_df.sort_values(by=\"date\")\n",
    "\n",
    "        # Use provided test dataframe and separate features and targets\n",
    "        X_train = train_df.drop([cls_target, reg_target], axis=1)\n",
    "        y_train = train_df[[cls_target, reg_target]]\n",
    "        X_test = test_df.drop([cls_target, reg_target], axis=1)\n",
    "        y_test = test_df[[cls_target, reg_target]]\n",
    "\n",
    "    # Separate classification and regression targets\n",
    "    y_train_cls = y_train[[cls_target]]\n",
    "    y_train_reg = y_train[[reg_target]]\n",
    "    y_test_cls = y_test[[cls_target]]\n",
    "    y_test_reg = y_test[[reg_target]]\n",
    "\n",
    "    return X_train, X_test, y_train_cls, y_test_cls, y_train_reg, y_test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_cls, y_test_cls, y_train_reg, y_test_reg = prepare_datasets(\n",
    "    df_2021_2022, \"CLS_TARGET\", \"REG_TARGET\", test_df=df_2022_2023\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_feature_set = [\n",
    "    \"home_opening_spread\",\n",
    "    \"opening_total\",\n",
    "    \"home_moneyline\",\n",
    "    \"road_moneyline\",\n",
    "]\n",
    "\n",
    "base_feature_set = [\n",
    "    \"day_of_season\",\n",
    "    \"home_team_rest\",\n",
    "    \"road_team_rest\",\n",
    "    \"home_win_pct\",\n",
    "    \"road_win_pct\",\n",
    "    \"home_win_pct_l2w\",\n",
    "    \"road_win_pct_l2w\",\n",
    "    \"home_avg_pts\",\n",
    "    \"road_avg_pts\",\n",
    "    \"home_avg_pts_l2w\",\n",
    "    \"road_avg_pts_l2w\",\n",
    "    \"home_avg_oeff\",\n",
    "    \"road_avg_oeff\",\n",
    "    \"home_avg_oeff_l2w\",\n",
    "    \"road_avg_oeff_l2w\",\n",
    "    \"home_avg_deff\",\n",
    "    \"road_avg_deff\",\n",
    "    \"home_avg_deff_l2w\",\n",
    "    \"road_avg_deff_l2w\",\n",
    "    \"home_avg_eFG%\",\n",
    "    \"road_avg_eFG%\",\n",
    "    \"home_avg_eFG%_l2w\",\n",
    "    \"road_avg_eFG%_l2w\",\n",
    "    \"home_avg_TOV%\",\n",
    "    \"road_avg_TOV%\",\n",
    "    \"home_avg_TOV%_l2w\",\n",
    "    \"road_avg_TOV%_l2w\",\n",
    "    \"home_avg_ORB%\",\n",
    "    \"road_avg_ORB%\",\n",
    "    \"home_avg_ORB%_l2w\",\n",
    "    \"road_avg_ORB%_l2w\",\n",
    "    \"home_avg_FT%\",\n",
    "    \"road_avg_FT%\",\n",
    "    \"home_avg_FT%_l2w\",\n",
    "    \"road_avg_FT%_l2w\",\n",
    "    \"home_avg_pts_allowed\",\n",
    "    \"road_avg_pts_allowed\",\n",
    "    \"home_avg_pts_allowed_l2w\",\n",
    "    \"road_avg_pts_allowed_l2w\",\n",
    "]\n",
    "\n",
    "lineup_vectors = [\"home_lineup_vector\", \"road_lineup_vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = base_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_vector_columns(df, vector_columns):\n",
    "    \"\"\"\n",
    "    Flatten vector columns into separate feature columns.\n",
    "\n",
    "    This function takes a DataFrame and a list of column names that store vector data as strings\n",
    "    (typically after being read from a CSV file), and returns a new DataFrame where the vectors\n",
    "    have been flattened into separate feature columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    vector_columns (list): A list of column names in df that store vector data as strings.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with vector columns flattened.\n",
    "    \"\"\"\n",
    "    for column in vector_columns:\n",
    "        if column not in df.columns:\n",
    "            continue\n",
    "        # Convert the string representation of the vector into a numpy array\n",
    "        df[column] = df[column].apply(\n",
    "            lambda x: np.array(x.strip(\"[]\").replace(\"\\n\", \" \").split(), dtype=float)\n",
    "        )\n",
    "\n",
    "        # Flatten the numpy array into separate columns\n",
    "        vector_df = pd.DataFrame(df[column].tolist(), index=df.index)\n",
    "        vector_df.columns = [f\"{column}_{i}\" for i in range(vector_df.shape[1])]\n",
    "\n",
    "        # Drop the original vector column and concatenate the new DataFrame\n",
    "        df = df.drop(column, axis=1)\n",
    "        df = pd.concat([df, vector_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten lineup vectors\n",
    "X_train = flatten_vector_columns(X_train, lineup_vectors)\n",
    "X_test = flatten_vector_columns(X_test, lineup_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_df = pd.concat([X_train, y_train_cls, y_train_reg], axis=1)\n",
    "combined_test_df = pd.concat([X_test, y_test_cls, y_test_reg], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1323 entries, 0 to 1322\n",
      "Data columns (total 41 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   day_of_season             1323 non-null   int64  \n",
      " 1   home_team_rest            1323 non-null   int64  \n",
      " 2   road_team_rest            1323 non-null   int64  \n",
      " 3   home_win_pct              1323 non-null   float64\n",
      " 4   road_win_pct              1323 non-null   float64\n",
      " 5   home_win_pct_l2w          1323 non-null   float64\n",
      " 6   road_win_pct_l2w          1323 non-null   float64\n",
      " 7   home_avg_pts              1323 non-null   float64\n",
      " 8   road_avg_pts              1323 non-null   float64\n",
      " 9   home_avg_pts_l2w          1323 non-null   float64\n",
      " 10  road_avg_pts_l2w          1323 non-null   float64\n",
      " 11  home_avg_oeff             1323 non-null   float64\n",
      " 12  road_avg_oeff             1323 non-null   float64\n",
      " 13  home_avg_oeff_l2w         1323 non-null   float64\n",
      " 14  road_avg_oeff_l2w         1323 non-null   float64\n",
      " 15  home_avg_deff             1323 non-null   float64\n",
      " 16  road_avg_deff             1323 non-null   float64\n",
      " 17  home_avg_deff_l2w         1323 non-null   float64\n",
      " 18  road_avg_deff_l2w         1323 non-null   float64\n",
      " 19  home_avg_eFG%             1323 non-null   float64\n",
      " 20  road_avg_eFG%             1323 non-null   float64\n",
      " 21  home_avg_eFG%_l2w         1323 non-null   float64\n",
      " 22  road_avg_eFG%_l2w         1323 non-null   float64\n",
      " 23  home_avg_TOV%             1323 non-null   float64\n",
      " 24  road_avg_TOV%             1323 non-null   float64\n",
      " 25  home_avg_TOV%_l2w         1323 non-null   float64\n",
      " 26  road_avg_TOV%_l2w         1323 non-null   float64\n",
      " 27  home_avg_ORB%             1323 non-null   float64\n",
      " 28  road_avg_ORB%             1323 non-null   float64\n",
      " 29  home_avg_ORB%_l2w         1323 non-null   float64\n",
      " 30  road_avg_ORB%_l2w         1323 non-null   float64\n",
      " 31  home_avg_FT%              1323 non-null   float64\n",
      " 32  road_avg_FT%              1323 non-null   float64\n",
      " 33  home_avg_FT%_l2w          1323 non-null   float64\n",
      " 34  road_avg_FT%_l2w          1323 non-null   float64\n",
      " 35  home_avg_pts_allowed      1323 non-null   float64\n",
      " 36  road_avg_pts_allowed      1323 non-null   float64\n",
      " 37  home_avg_pts_allowed_l2w  1323 non-null   float64\n",
      " 38  road_avg_pts_allowed_l2w  1323 non-null   float64\n",
      " 39  CLS_TARGET                1323 non-null   bool   \n",
      " 40  REG_TARGET                1323 non-null   int64  \n",
      "dtypes: bool(1), float64(36), int64(4)\n",
      "memory usage: 425.1 KB\n"
     ]
    }
   ],
   "source": [
    "combined_train_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1320 entries, 0 to 1319\n",
      "Data columns (total 41 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   day_of_season             1320 non-null   int64  \n",
      " 1   home_team_rest            1320 non-null   int64  \n",
      " 2   road_team_rest            1320 non-null   int64  \n",
      " 3   home_win_pct              1320 non-null   float64\n",
      " 4   road_win_pct              1320 non-null   float64\n",
      " 5   home_win_pct_l2w          1320 non-null   float64\n",
      " 6   road_win_pct_l2w          1320 non-null   float64\n",
      " 7   home_avg_pts              1320 non-null   float64\n",
      " 8   road_avg_pts              1320 non-null   float64\n",
      " 9   home_avg_pts_l2w          1320 non-null   float64\n",
      " 10  road_avg_pts_l2w          1320 non-null   float64\n",
      " 11  home_avg_oeff             1320 non-null   float64\n",
      " 12  road_avg_oeff             1320 non-null   float64\n",
      " 13  home_avg_oeff_l2w         1320 non-null   float64\n",
      " 14  road_avg_oeff_l2w         1320 non-null   float64\n",
      " 15  home_avg_deff             1320 non-null   float64\n",
      " 16  road_avg_deff             1320 non-null   float64\n",
      " 17  home_avg_deff_l2w         1320 non-null   float64\n",
      " 18  road_avg_deff_l2w         1320 non-null   float64\n",
      " 19  home_avg_eFG%             1320 non-null   float64\n",
      " 20  road_avg_eFG%             1320 non-null   float64\n",
      " 21  home_avg_eFG%_l2w         1320 non-null   float64\n",
      " 22  road_avg_eFG%_l2w         1320 non-null   float64\n",
      " 23  home_avg_TOV%             1320 non-null   float64\n",
      " 24  road_avg_TOV%             1320 non-null   float64\n",
      " 25  home_avg_TOV%_l2w         1320 non-null   float64\n",
      " 26  road_avg_TOV%_l2w         1320 non-null   float64\n",
      " 27  home_avg_ORB%             1320 non-null   float64\n",
      " 28  road_avg_ORB%             1320 non-null   float64\n",
      " 29  home_avg_ORB%_l2w         1320 non-null   float64\n",
      " 30  road_avg_ORB%_l2w         1320 non-null   float64\n",
      " 31  home_avg_FT%              1320 non-null   float64\n",
      " 32  road_avg_FT%              1320 non-null   float64\n",
      " 33  home_avg_FT%_l2w          1320 non-null   float64\n",
      " 34  road_avg_FT%_l2w          1320 non-null   float64\n",
      " 35  home_avg_pts_allowed      1320 non-null   float64\n",
      " 36  road_avg_pts_allowed      1320 non-null   float64\n",
      " 37  home_avg_pts_allowed_l2w  1320 non-null   float64\n",
      " 38  road_avg_pts_allowed_l2w  1320 non-null   float64\n",
      " 39  CLS_TARGET                1320 non-null   bool   \n",
      " 40  REG_TARGET                1320 non-null   int64  \n",
      "dtypes: bool(1), float64(36), int64(4)\n",
      "memory usage: 424.1 KB\n"
     ]
    }
   ],
   "source": [
    "combined_test_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = mean_absolute_error(train_predictions_reg, y_train_reg)\n",
    "train_r2 = r2_score(train_predictions_reg, y_train_reg)\n",
    "\n",
    "test_mae = mean_absolute_error(test_predictions_reg, y_test_reg)\n",
    "test_r2 = r2_score(test_predictions_reg, y_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 11.81\n",
      "Train R2: -30.65\n",
      "Test MAE: 10.73\n",
      "Test R2: -38.40\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Train R2: {train_r2:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f}\")\n",
    "print(f\"Test R2: {test_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regression_MLP_11.81_10.73_2024-01-03_15-50-13'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_type = \"Regression\"\n",
    "base_model = \"MLP\"\n",
    "train_performance = round(train_mae, 2)\n",
    "test_performance = round(test_mae, 2)\n",
    "\n",
    "model_id = f\"{problem_type}_{base_model}_{train_performance}_{test_performance}_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
